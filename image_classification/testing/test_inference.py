# -*- coding: utf-8 -*-
"""inference_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1beFLhjMu-oeodUsaahGkKsJZlk4Q0N_7
"""

import torch
import torch.nn as nn
from torchvision.transforms import transforms
from torch.autograd import Variable
# from torchvision.models import squeezenet1_1
import requests
import shutil
from io import open, BytesIO
import os
from PIL import Image, ImageFile
import json

# todo import this

class Unit(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(Unit, self).__init__()

        self.conv = nn.Conv2d(in_channels=in_channels, kernel_size=3, out_channels=out_channels,
                              stride=1, padding=1)
        self.bn = nn.BatchNorm2d(num_features=out_channels)
        self.relu = nn.ReLU()

    def forward(self, input):
        output = self.conv(input)
        output = self.bn(output)
        output = self.relu(output)

        return output

class SimpleNet(nn.Module):
    def __init__(self, num_classes=5):
        super(SimpleNet, self).__init__()

        # Create 14 layers of the unit with max pooling in between
        self.unit1 = Unit(in_channels=3, out_channels=32)
        self.unit2 = Unit(in_channels=32, out_channels=32)
        self.unit3 = Unit(in_channels=32, out_channels=32)

        self.pool1 = nn.MaxPool2d(kernel_size=2)

        self.unit4 = Unit(in_channels=32, out_channels=64)
        self.unit5 = Unit(in_channels=64, out_channels=64)
        self.unit6 = Unit(in_channels=64, out_channels=64)
        self.unit7 = Unit(in_channels=64, out_channels=64)

        self.pool2 = nn.MaxPool2d(kernel_size=2)

        self.unit8 = Unit(in_channels=64, out_channels=128)
        self.unit9 = Unit(in_channels=128, out_channels=128)
        self.unit10 = Unit(in_channels=128, out_channels=128)
        self.unit11 = Unit(in_channels=128, out_channels=128)

        self.pool3 = nn.MaxPool2d(kernel_size=2)

        self.unit12 = Unit(in_channels=128, out_channels=128)
        self.unit13 = Unit(in_channels=128, out_channels=128)
        self.unit14 = Unit(in_channels=128, out_channels=128)

        # Computes the average of all activations in each channel
        self.avgpool = nn.AvgPool2d(kernel_size=4)
        
        # Add all the units into the Sequential layer in exact order
        self.net = nn.Sequential(self.unit1, self.unit2, self.unit3, self.pool1,
                                 self.unit4, self.unit5, self.unit6,self.unit7, 
                                 self.pool2, self.unit8, self.unit9, self.unit10, self.unit11,
                                 self.pool3, self.unit12, self.unit13, self.unit14, self.avgpool)

        self.fc = nn.Linear(in_features=128, out_features=num_classes)

    def forward(self, input):
        output = self.net(input)
        output = output.view(-1,128)
        output = self.fc(output)
        return output


# Replace with my own model once I train it
"""
checkpoint = torch.load("pathtosavedmodel")
model = SimpleNet(num_classes=10)

model.load_state_dict(checkpoint)
model.eval()

If we're running prediction w a model trained on cifar10,
change transforms.CenterCrop(224) to transforms.Resize(32)
"""

# model = squeezenet1_1(pretrained=True)
# model.eval()

# from user import SimpleNet
# from .user import User
# from .testing import SimpleNet

path = "test_classifier.pth"
checkpoint = torch.load(path)
model = SimpleNet(num_classes=10)
model.load_state_dict(checkpoint)
model.eval()
print(model)

def predict_image(image_path):
    print('in predict_image image_path: {}'.format(image_path))

    image = Image.open(image_path)

    # Define transformations for the image, should (note that imagenet models are trained with image size 224)
    transformation = transforms.Compose([
        # transforms.CenterCrop(224),
        transforms.Resize(32),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))

    ])

    # Preprocess the image
    image_tensor = transformation(image).float()

    # Add an extra batch dimension since pytorch treats all images as batches
    image_tensor = image_tensor.unsqueeze_(0)

    if torch.cuda.is_available():
        image_tensor.cuda()

    # Turn the input into a Variable
    input = Variable(image_tensor)

    # Predict the class of the image
    output = model(input)

    index = output.data.numpy().argmax()

    return index

if __name__ == "__main__":

    # imagefile = "image.png"
    # imagefile = "horse5.png"  # 7
    imagefile = "bird6.png"     # 2

    imagepath = os.path.join(os.getcwd(), imagefile)
#     # Download image if it doesn't exist
#     if not os.path.exists(imagepath):
#         data = requests.get(
#             "https://github.com/OlafenwaMoses/ImageAI/raw/master/images/3.jpg", stream=True)

#         with open(imagepath, "wb") as file:
#             shutil.copyfileobj(data.raw, file)

#         del data

    print('imagepath: {}'.format(imagepath))

    # Run prediction function and obtain predicted class index
    index = predict_image(imagepath)
    print('index: {}'.format(index))
    
    index_file = "imagenet_class_index.json"

    indexpath = os.path.join(os.getcwd(), index_file)
#     # Download class index if it doesn't exist
#     if not os.path.exists(indexpath):
#         data = requests.get('https://github.com/OlafenwaMoses/ImageAI/raw/master/imagenet_class_index.json')

#         with open(indexpath, "w", encoding="utf-8") as file:
#             file.write(data.text)

    print('indexpath: {}'.format(indexpath))
    # class_map = json.load(open(indexpath))
    
    # prediction = class_map[str(index)][1]

    # print("Predicted Class ", prediction)